name: "ResNet-18"

## Training Stage
layer { name: "left_data" type: "ImageData" top: "left_data" top: "label" 
	include { phase: TRAIN } 
	transform_param { mirror: true mean_value: 26.0917  mean_value: 48.3404 mean_value: 76.3456 } 
	image_data_param {
        source: "./data_lst/left_train_label.txt"	#the path of left_text files in ./data_lst
		root_folder: "the path of training set"		#e.g "OIA-ODIR/Training Set/Images/"
        batch_size: 2
        new_height: 224
		new_width: 224
		shuffle: true
		shuffle_same: true
		label_dim: 8
    }
}
layer { name: "right_data" type: "ImageData" top: "right_data" top: "redundancy_label" 
	include { phase: TRAIN } 
	transform_param { mirror: true mean_value: 26.0917  mean_value: 48.3404 mean_value: 76.3456 } 
	image_data_param {
        source: "./data_lst/right_train_label.txt"	#the path of right_text files in ./data_lst
		root_folder: "the path of training set"		#e.g "OIA-ODIR/Training Set/Images/"
        batch_size: 2
        new_height: 224
		new_width: 224
		shuffle: true
		shuffle_same: true
		label_dim: 8
    }
}
layer{ name: "silence_redundancy_label" type: "Silence" bottom: "redundancy_label" include: { phase: TRAIN } }

## Test Stage
layer { name: "left_data" type: "ImageData" top: "left_data" top: "label"
    include { phase: TEST }
	transform_param { mirror: true mean_value: 26.0917  mean_value: 48.3404 mean_value: 76.3456 } 
    image_data_param {
        source: "./data_lst/left_offtest_label.txt"		#the path of left_text files in ./data_lst
		root_folder: "the path of offsite testing set"	#e.g "OIA-ODIR/Off-site Test Set/Images/"
        batch_size: 2
        new_height: 224
		new_width: 224
		shuffle: false
		label_dim: 8
    }
}
layer { name: "right_data" type: "ImageData" top: "right_data" top: "redundancy_label"
    include { phase: TEST }
	transform_param { mirror: true mean_value: 26.0917  mean_value: 48.3404 mean_value: 76.3456 } 
    image_data_param {
        source: "./data_lst/right_offtest_label.txt"	#the path of right_text files in ./data_lst
		root_folder: "the path of offsite testing set"	#e.g "OIA-ODIR/Off-site Test Set/Images/"
        batch_size: 2
        new_height: 224
		new_width: 224
		shuffle: false
		label_dim: 8
    }
}
layer{ name: "silence_redundancy_label" type: "Silence" bottom: "redundancy_label" include: { phase: TEST } }


# concat left and right eyes
layer {
  name: "concat_data"
  type: "Concat"
  bottom: "left_data"
  bottom: "right_data"
  top: "data"
  concat_param {
    concat_dim: 0
	#axis: 0
  }
}


# Slice Layer
layer {
	name: "slice_label"
	type: "Slice"
	bottom: "label"
	top: "label_1"
	top: "label_2"
	top: "label_3"
	top: "label_4"
	top: "label_5"
	top: "label_6"
	top: "label_7"
	top: "label_8"
	slice_param {
		axis: 1
		slice_point: 1
		slice_point: 2
		slice_point: 3
		slice_point: 4
		slice_point: 5
		slice_point: 6
		slice_point: 7
	}
}

layer {
    bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 7
        pad: 3
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
}

layer {
    bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
        kernel_size: 3
        stride: 2
        pool: MAX
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2b"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a"
    bottom: "res2b_branch2b"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch1"
    bottom: "res3a_branch2b"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a"
    bottom: "res3b_branch2b"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch1"
    bottom: "res4a_branch2b"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a"
    bottom: "res4b_branch2b"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b"
    top: "res5a_branch1"
    name: "res5a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "bn5a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "scale5a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b"
    top: "res5a_branch2a"
    name: "res5a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "bn5a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "scale5a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "res5a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2b"
    name: "res5a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "bn5a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "scale5a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch1"
    bottom: "res5a_branch2b"
    top: "res5a"
    name: "res5a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res5a"
    top: "res5a"
    name: "res5a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a"
    top: "res5b_branch2a"
    name: "res5b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "bn5b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "scale5b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "res5b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2b"
    name: "res5b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "bn5b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "scale5b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a"
    bottom: "res5b_branch2b"
    top: "res5b"
    name: "res5b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res5b"
    top: "res5b"
    name: "res5b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b"
    top: "pool5"
    name: "pool5"
    type: "Pooling"
    pooling_param {
        kernel_size: 7
        stride: 1
        pool: AVE
    }
}
#layer {
#    bottom: "pool5"
#    top: "pool6"
#    name: "pool6"
#    type: "Pooling"
#    pooling_param {
#        kernel_size: 2
#        stride: 1
#        pool: MAX
#    }
#}

layer {
	name: "dropout"
	type: "Dropout"
	bottom: "pool5"
	top: "dropout"
	dropout_param {
		dropout_ratio: 0.5
	}
}

# Slice Feature
layer {
	name: "slice_feature"
	type: "Slice"
	bottom: "dropout"
	top: "fc7_1_left"
	top: "fc7_2_left"
	top: "fc7_1_right"
	top: "fc7_2_right"
	slice_param {
		axis: 0
		slice_point: 1
		slice_point: 2
		slice_point: 3
	}
}

#Concat left and right features
#layer {
#  name: "concat_fc7_1"
#  type: "Concat"
#  bottom: "fc7_1_left"
#  bottom: "fc7_1_right"
#  top: "fc7_1"
#  concat_param {
#    concat_dim: 1
#	#axis: 1
#  }
#}
#layer {
#  name: "concat_fc7_2"
#  type: "Concat"
#  bottom: "fc7_2_left"
#  bottom: "fc7_2_right"
#  top: "fc7_2"
#  concat_param {
#    concat_dim: 1
#	#axis: 1
#  }
#}

#SUM or PROD operating
layer { name: "eltwise_fc7_1" type: "Eltwise" bottom: "fc7_1_left" bottom: "fc7_1_right" top: "fc7_1" 
	eltwise_param { 
		operation: SUM 
		#operation: PROD 
	} 
}
layer { name: "eltwise_fc7_2" type: "Eltwise" bottom: "fc7_2_left" bottom: "fc7_2_right" top: "fc7_2" 
	eltwise_param { 
		operation: SUM 
		#operation: PROD 
	} 
}
layer {
  name: "concat_fc7"
  type: "Concat"
  bottom: "fc7_1"
  bottom: "fc7_2"
  top: "fc8"
  concat_param {
    concat_dim: 0
  }
}

layer {name: "ip_1" type: "InnerProduct" bottom: "fc8" top: "ip_1" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_2" type: "InnerProduct" bottom: "fc8" top: "ip_2" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_3" type: "InnerProduct" bottom: "fc8" top: "ip_3" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_4" type: "InnerProduct" bottom: "fc8" top: "ip_4" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_5" type: "InnerProduct" bottom: "fc8" top: "ip_5" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_6" type: "InnerProduct" bottom: "fc8" top: "ip_6" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_7" type: "InnerProduct" bottom: "fc8" top: "ip_7" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer {name: "ip_8" type: "InnerProduct" bottom: "fc8" top: "ip_8" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } inner_product_param { num_output: 2 weight_filler {type: "gaussian" std: 0.005 } bias_filler { type: "constant" value: 0.1 } } }

layer { name: "loss1" type: "SoftmaxWithLoss" bottom: "ip_1" bottom: "label_1" top: "loss1" }
layer { name: "accuracy1" type: "Accuracy" bottom: "ip_1" bottom: "label_1" top: "accuracy1" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_1" type: "ConfusionMatrix" bottom: "ip_1" bottom: "label_1" top: "confusion_matrix_1" include { phase: TEST } }

layer { name: "loss2" type: "SoftmaxWithLoss" bottom: "ip_2" bottom: "label_2" top: "loss2" }
layer { name: "accuracy2" type: "Accuracy" bottom: "ip_2" bottom: "label_2" top: "accuracy2" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_2" type: "ConfusionMatrix" bottom: "ip_2" bottom: "label_2" top: "confusion_matrix_2" include { phase: TEST } }

layer { name: "loss3" type: "SoftmaxWithLoss" bottom: "ip_3" bottom: "label_3" top: "loss3" }
layer { name: "accuracy3" type: "Accuracy" bottom: "ip_3" bottom: "label_3" top: "accuracy3" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_3" type: "ConfusionMatrix" bottom: "ip_3" bottom: "label_3" top: "confusion_matrix_3" include { phase: TEST } }

layer { name: "loss4" type: "SoftmaxWithLoss" bottom: "ip_4" bottom: "label_4" top: "loss4" }
layer { name: "accuracy4" type: "Accuracy" bottom: "ip_4" bottom: "label_4" top: "accuracy4" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_4" type: "ConfusionMatrix" bottom: "ip_4" bottom: "label_4" top: "confusion_matrix_4" include { phase: TEST } }

layer { name: "loss5" type: "SoftmaxWithLoss" bottom: "ip_5" bottom: "label_5" top: "loss5" }
layer { name: "accuracy5" type: "Accuracy" bottom: "ip_5" bottom: "label_5" top: "accuracy5" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_5" type: "ConfusionMatrix" bottom: "ip_5" bottom: "label_5" top: "confusion_matrix_5" include { phase: TEST } }

layer { name: "loss6" type: "SoftmaxWithLoss" bottom: "ip_6" bottom: "label_6" top: "loss6" }
layer { name: "accuracy6" type: "Accuracy" bottom: "ip_6" bottom: "label_6" top: "accuracy6" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_6" type: "ConfusionMatrix" bottom: "ip_6" bottom: "label_6" top: "confusion_matrix_6" include { phase: TEST } }

layer { name: "loss7" type: "SoftmaxWithLoss" bottom: "ip_7" bottom: "label_7" top: "loss7" }
layer { name: "accuracy7" type: "Accuracy" bottom: "ip_7" bottom: "label_7" top: "accuracy7" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_7" type: "ConfusionMatrix" bottom: "ip_7" bottom: "label_7" top: "confusion_matrix_7" include { phase: TEST } }

layer { name: "loss8" type: "SoftmaxWithLoss" bottom: "ip_8" bottom: "label_8" top: "loss8" }
layer { name: "accuracy8" type: "Accuracy" bottom: "ip_8" bottom: "label_8" top: "accuracy8" accuracy_param { top_k: 1 } include { phase: TEST } }
layer { name: "confusion_matrix_8" type: "ConfusionMatrix" bottom: "ip_8" bottom: "label_8" top: "confusion_matrix_8" include { phase: TEST } }

